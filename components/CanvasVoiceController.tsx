/**
 * Canvas Voice Controller - ç”»å¸ƒè¯­éŸ³æ§åˆ¶ç»„ä»¶
 * ä½¿ç”¨ç¥é©¬APIçš„Realtimeè¯­éŸ³å¯¹è¯åŠŸèƒ½ï¼Œæ— éœ€è¿æ¥è°·æ­ŒæœåŠ¡
 * æ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«å’ŒAIå¯¹è¯
 * æ³¨æ„ï¼šæ­¤ç»„ä»¶ä»…è´Ÿè´£è¯­éŸ³æŠ€æœ¯å®ç°ï¼ŒUIäº¤äº’ç”±CaocaoAIChatç»Ÿä¸€ç®¡ç†
 */

import React, { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, Loader2 } from 'lucide-react';
import { Block } from '../types';
import { voiceCanvasReporter, VoiceModuleCommand } from '../services/VoiceCanvasReporter';

// ç¥é©¬API Realtime WebSocketæ¥å£ - åŸºäºå®Œæ•´æ–‡æ¡£è§„èŒƒ
interface RealtimeSession {
  ws: WebSocket | null;
  sessionId: string;
  isConnected: boolean;
}

interface RealtimeEvent {
  type: string;
  event_id?: string;
  // Session events
  session?: {
    id?: string;
    object?: string;
    model?: string;
    modalities?: string[];
    instructions?: string;
    voice?: string;
    input_audio_format?: string;
    output_audio_format?: string;
    input_audio_transcription?: {
      enabled?: boolean;
      model?: string;
    };
    turn_detection?: {
      type?: string;
      threshold?: number;
      prefix_padding_ms?: number;
      silence_duration_ms?: number;
    };
    tools?: any[];
    tool_choice?: string;
    temperature?: number;
    max_output_tokens?: number | string;
  };
  // Response events
  response?: {
    id?: string;
    object?: string;
    status?: string;
    status_details?: any;
    output?: any[];
    usage?: any;
  };
  response_id?: string;
  output_index?: number;
  // Item events
  item?: {
    id?: string;
    object?: string;
    type?: string;
    status?: string;
    role?: string;
    content?: any[];
    call_id?: string;
    name?: string;
    arguments?: string;
    output?: string;
  };
  item_id?: string;
  content_index?: number;
  // Audio events
  audio?: string;
  audio_start_ms?: number;
  audio_end_ms?: number;
  // Text events
  transcript?: string;
  text?: string;
  delta?: string;
  // Function call events
  call_id?: string;
  arguments?: string;
  // Error events
  error?: {
    type?: string;
    code?: string;
    message?: string;
    param?: string;
    event_id?: string;
  };
  // Content part events
  part?: {
    type?: string;
    text?: string;
    audio?: string;
    transcript?: string;
  };
  // Conversation events
  conversation?: {
    id?: string;
    object?: string;
  };
  previous_item_id?: string;
  // Rate limits
  rate_limits?: Array<{
    name?: string;
    limit?: number;
    remaining?: number;
    reset_seconds?: number;
  }>;
}

// TypeScript declarations for Web Speech API (å¤‡ç”¨æ–¹æ¡ˆ)
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition;
    webkitSpeechRecognition: typeof SpeechRecognition;
  }
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult;
  length: number;
}

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  length: number;
  isFinal: boolean;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

declare var SpeechRecognition: {
  prototype: SpeechRecognition;
  new(): SpeechRecognition;
};

interface VoiceCommand {
  command: 'generate_text' | 'generate_image' | 'generate_video' | 'add_to_canvas' | 'unknown';
  text: string;
  content: string;
  params?: {
    aspectRatio?: string;
    style?: string;
    duration?: number;
  };
}

interface CanvasVoiceControllerProps {
  onCommand: (command: VoiceCommand) => void;
  lang?: 'zh' | 'en';
  wakeWord?: string;
  position?: { x: number; y: number };
  theme?: 'light' | 'dark';
  isActive?: boolean;
  apiSettings?: {
    provider: string;
    apiKey: string;
    baseUrl: string;
  };
  // æ–°å¢ï¼šæ¶ˆæ¯å›è°ƒï¼Œç”¨äºä¸CaocaoAIChaté€šä¿¡
  onMessage?: (role: 'user' | 'assistant', content: string, type?: 'voice' | 'system') => void;
  onStatusChange?: (status: 'connecting' | 'connected' | 'disconnected' | 'error', message?: string) => void;
  // æ–°å¢ï¼šç”»å¸ƒçŠ¶æ€å’Œæ¨¡å—æ“ä½œ
  blocks?: Block[];
  onModuleAction?: (action: string, moduleId?: string, params?: any) => void;
  // æ–°å¢ï¼šå¤–éƒ¨æ¶ˆæ¯æ›´æ–°å‡½æ•°
  onDisplayMessageUpdate?: (addMessage: (role: 'user' | 'assistant', content: string) => void) => void;
}

const CanvasVoiceController: React.FC<CanvasVoiceControllerProps> = ({
  onCommand,
  lang = 'zh',
  wakeWord = 'æ›¹æ“',
  position = { x: 20, y: 20 },
  theme = 'light',
  isActive = false,
  apiSettings,
  onMessage,
  onStatusChange,
  blocks = [],
  onModuleAction,
  onDisplayMessageUpdate
}) => {
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [error, setError] = useState<string>('');
  const [realtimeSession, setRealtimeSession] = useState<RealtimeSession>({
    ws: null,
    sessionId: '',
    isConnected: false
  });
  const [useRealtimeAPI, setUseRealtimeAPI] = useState<boolean>(true);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [errorCount, setErrorCount] = useState<number>(0); // é”™è¯¯è®¡æ•°å™¨
  const [lastErrorTime, setLastErrorTime] = useState<number>(0); // æœ€åé”™è¯¯æ—¶é—´
  
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const t = {
    zh: {
      wakeUp: `ç‚¹å‡»å¼€å§‹è¯­éŸ³å¯¹è¯`,
      listening: 'è¯­éŸ³å¯¹è¯ä¸­...',
      processing: 'æ­£åœ¨å¤„ç†...',
      error: 'é”™è¯¯',
      noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«',
      micPermission: 'éœ€è¦éº¦å…‹é£æƒé™',
      chatTitle: 'è¯­éŸ³å¯¹è¯',
      inputPlaceholder: 'è¾“å…¥æ¶ˆæ¯æˆ–ç‚¹å‡»è¯­éŸ³å¯¹è¯...',
      send: 'å‘é€',
      openRealtimeChat: 'æ‰“å¼€è¯­éŸ³å¯¹è¯',
      realtimeMode: 'å®æ—¶è¯­éŸ³æ¨¡å¼',
      fallbackMode: 'æµè§ˆå™¨è¯­éŸ³æ¨¡å¼',
      apiKeyRequired: 'APIå¯†é’¥æœªé…ç½®'
    },
    en: {
      wakeUp: `Click to start voice chat`,
      listening: 'Voice chatting...',
      processing: 'Processing...',
      error: 'Error',
      noSupport: 'Speech recognition not supported',
      micPermission: 'Microphone permission required',
      chatTitle: 'Voice Chat',
      inputPlaceholder: 'Type message or click voice chat...',
      send: 'Send',
      openRealtimeChat: 'Open Voice Chat',
      realtimeMode: 'Realtime Voice Mode',
      fallbackMode: 'Browser Voice Mode',
      apiKeyRequired: 'API Key Required'
    }
  };

  const currentLang = t[lang];

  // ç›‘å¬æ¿€æ´»çŠ¶æ€å˜åŒ–ï¼Œè‡ªåŠ¨å¼€å§‹/åœæ­¢ç›‘å¬
  useEffect(() => {
    if (isActive && !isListening && !isProcessing) {
      console.log('[CanvasVoiceController] è¯­éŸ³æ§åˆ¶æ¿€æ´»ï¼Œè‡ªåŠ¨å¼€å§‹ç›‘å¬');
      if (useRealtimeAPI && apiSettings?.apiKey && apiSettings.apiKey !== 'PLACEHOLDER_API_KEY') {
        // ä½¿ç”¨ç¥é©¬API Realtimeæ¨¡å¼
        initializeRealtimeChat();
      } else {
        // é™çº§åˆ°æµè§ˆå™¨è¯­éŸ³è¯†åˆ«
        setUseRealtimeAPI(false);
        initializeBrowserSpeech();
      }
    } else if (!isActive && (isListening || realtimeSession.isConnected)) {
      console.log('[CanvasVoiceController] è¯­éŸ³æ§åˆ¶å…³é—­ï¼Œåœæ­¢ç›‘å¬');
      stopListening();
    }
  }, [isActive]);

  // åˆå§‹åŒ–ç¥é©¬API Realtime WebSocketè¿æ¥
  const initializeRealtimeChat = async () => {
    if (!apiSettings?.apiKey || apiSettings.apiKey === 'PLACEHOLDER_API_KEY') {
      setError(currentLang.apiKeyRequired);
      onStatusChange?.('error', currentLang.apiKeyRequired);
      handleMessageUpdate('assistant', `âŒ ${currentLang.apiKeyRequired}ï¼

ğŸ”‘ è¯·å…ˆé…ç½®ç¥é©¬APIå¯†é’¥ï¼š
1. ç‚¹å‡»å³ä¾§è¾¹æ çš„"è®¾ç½®"âš™ï¸æŒ‰é’®
2. åœ¨"APIæä¾›å•†é…ç½®"ä¸­è¾“å…¥ç¥é©¬APIå¯†é’¥
3. ç‚¹å‡»"ä¿å­˜é…ç½®"

ğŸ’¡ é…ç½®å®Œæˆåå³å¯ä½¿ç”¨å®æ—¶è¯­éŸ³å¯¹è¯åŠŸèƒ½ï¼`, 'system');
      return;
    }

    try {
      setIsProcessing(true);
      setError('');
      onStatusChange?.('connecting', 'æ­£åœ¨è¿æ¥ç¥é©¬API Realtime...');
      
      console.log('[CanvasVoiceController] åˆå§‹åŒ–ç¥é©¬API Realtime WebSocketè¿æ¥');
      
      // æ„å»ºWebSocket URL - å°†HTTP URLè½¬æ¢ä¸ºWebSocket URL
      const wsUrl = apiSettings.baseUrl.replace('http://', 'ws://').replace('https://', 'wss://') + '/v1/realtime';
      
      console.log('[CanvasVoiceController] è¿æ¥åˆ°:', wsUrl);
      
      // åˆ›å»ºWebSocketè¿æ¥
      const ws = new WebSocket(wsUrl);
      
      const sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      
      ws.onopen = () => {
        console.log('[CanvasVoiceController] âœ… WebSocketè¿æ¥å·²å»ºç«‹');
        
        setRealtimeSession({
          ws,
          sessionId,
          isConnected: true
        });
        
        // å‘é€session.updateäº‹ä»¶é…ç½®ä¼šè¯ - ä½¿ç”¨å®Œæ•´çš„ç¥é©¬APIè§„èŒƒ
        const sessionUpdateEvent = {
          event_id: `event_${Date.now()}`,
          type: 'session.update',
          session: {
            modalities: ['text', 'audio'],
            instructions: `ä½ æ˜¯æ›¹æ“ï¼Œä¸€ä¸ªä¸“ä¸šçš„AIç”»å¸ƒåŠ©æ‰‹ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³ä¸ä½ å¯¹è¯ï¼Œä½ éœ€è¦ï¼š
1. ç†è§£ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚
2. å¸®åŠ©ç”¨æˆ·ç”Ÿæˆæ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘å†…å®¹
3. å°†å†…å®¹æ·»åŠ åˆ°ç”»å¸ƒä¸Š
4. ç”¨ç®€æ´å‹å¥½çš„è¯­è¨€å›å¤

å½“ç”¨æˆ·è¦æ±‚ç”Ÿæˆå†…å®¹æ—¶ï¼Œè¯·æ˜ç¡®è¯´æ˜ä½ å°†æ‰§è¡Œçš„æ“ä½œã€‚`,
            voice: 'alloy',
            input_audio_format: 'pcm16',
            output_audio_format: 'pcm16',
            input_audio_transcription: {
              model: 'whisper-1'
            },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 200
            },
            temperature: 0.8,
            max_output_tokens: 'inf'
          }
        };
        
        ws.send(JSON.stringify(sessionUpdateEvent));
        console.log('[CanvasVoiceController] å·²å‘é€session.updateé…ç½®');
        
        setIsListening(true);
        onStatusChange?.('connected', 'å®æ—¶è¯­éŸ³å¯¹è¯å·²è¿æ¥');
        
        handleMessageUpdate('assistant', `âœ… å®æ—¶è¯­éŸ³å¯¹è¯å·²è¿æ¥ï¼

ğŸ¤ ç°åœ¨ä½ å¯ä»¥ï¼š
1. ç›´æ¥å¯¹ç€éº¦å…‹é£è¯´è¯
2. æˆ‘ä¼šå®æ—¶å¬å–å¹¶å›å¤
3. è¯´å‡ºåˆ›ä½œéœ€æ±‚ï¼Œæˆ‘ä¼šç”Ÿæˆå†…å®¹åˆ°ç”»å¸ƒ

ğŸ’¡ è¯•è¯•è¯´ï¼š"æ›¹æ“ï¼Œå¸®æˆ‘ç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡"`, 'system');
        
        // å¼€å§‹å½•éŸ³
        startAudioRecording();
      };
      
      ws.onmessage = (event) => {
        try {
          const data: RealtimeEvent = JSON.parse(event.data);
          handleRealtimeEvent(data);
        } catch (error) {
          console.error('[CanvasVoiceController] è§£æWebSocketæ¶ˆæ¯å¤±è´¥:', error);
        }
      };
      
      ws.onerror = (error) => {
        console.error('[CanvasVoiceController] WebSocketé”™è¯¯:', error);
        setError('WebSocketè¿æ¥é”™è¯¯');
        onStatusChange?.('error', 'WebSocketè¿æ¥é”™è¯¯');
        
        onMessage?.('assistant', `âŒ å®æ—¶è¯­éŸ³è¿æ¥å‡ºç°é—®é¢˜

ğŸ”„ æ­£åœ¨å°è¯•é™çº§åˆ°æµè§ˆå™¨è¯­éŸ³æ¨¡å¼...`, 'system');
        
        // é™çº§åˆ°æµè§ˆå™¨è¯­éŸ³è¯†åˆ«
        setUseRealtimeAPI(false);
        setTimeout(() => initializeBrowserSpeech(), 1000);
      };
      
      ws.onclose = (event) => {
        console.log('[CanvasVoiceController] WebSocketè¿æ¥å·²å…³é—­:', event.code, event.reason);
        
        setRealtimeSession({
          ws: null,
          sessionId: '',
          isConnected: false
        });
        
        setIsListening(false);
        onStatusChange?.('disconnected', 'è¯­éŸ³è¿æ¥å·²æ–­å¼€');
        
        if (event.code !== 1000) { // éæ­£å¸¸å…³é—­
          onMessage?.('assistant', 'ğŸ”Œ è¯­éŸ³è¿æ¥å·²æ–­å¼€ï¼Œç‚¹å‡»é‡æ–°è¿æ¥æˆ–ä½¿ç”¨æ–‡å­—è¾“å…¥ã€‚', 'system');
        }
      };
      
    } catch (error) {
      console.error('[CanvasVoiceController] Realtime WebSocketåˆå§‹åŒ–å¤±è´¥:', error);
      setError('Realtimeè¿æ¥åˆå§‹åŒ–å¤±è´¥');
      onStatusChange?.('error', 'Realtimeè¿æ¥åˆå§‹åŒ–å¤±è´¥');
      
      // é™çº§åˆ°æµè§ˆå™¨è¯­éŸ³è¯†åˆ«
      onMessage?.('assistant', `âš ï¸ å®æ—¶è¯­éŸ³è¿æ¥å¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ°æµè§ˆå™¨è¯­éŸ³æ¨¡å¼ã€‚

ğŸ”„ é”™è¯¯ä¿¡æ¯ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}

ğŸ’¡ ä½ ä»ç„¶å¯ä»¥ä½¿ç”¨æµè§ˆå™¨çš„è¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚`, 'system');
      
      setUseRealtimeAPI(false);
      setTimeout(() => initializeBrowserSpeech(), 1000);
    } finally {
      setIsProcessing(false);
    }
  };

  // å¤„ç†Realtimeäº‹ä»¶ - åŸºäºå®Œæ•´çš„ç¥é©¬APIæ–‡æ¡£
  const handleRealtimeEvent = (event: RealtimeEvent) => {
    console.log('[CanvasVoiceController] æ”¶åˆ°Realtimeäº‹ä»¶:', event.type, event);
    
    switch (event.type) {
      // Session events
      case 'session.created':
        console.log('[CanvasVoiceController] ä¼šè¯å·²åˆ›å»º:', event.session?.id);
        break;
        
      case 'session.updated':
        console.log('[CanvasVoiceController] ä¼šè¯é…ç½®å·²æ›´æ–°');
        break;
        
      // Conversation events
      case 'conversation.created':
        console.log('[CanvasVoiceController] å¯¹è¯å·²åˆ›å»º:', event.conversation?.id);
        break;
        
      case 'conversation.item.created':
        console.log('[CanvasVoiceController] å¯¹è¯é¡¹å·²åˆ›å»º:', event.item?.id);
        break;
        
      case 'conversation.item.input_audio_transcription.completed':
        if (event.transcript && event.transcript.trim().length > 0) {
          handleTranscriptionComplete(event.transcript.trim());
        } else {
          console.log('[CanvasVoiceController] æ”¶åˆ°ç©ºçš„è½¬å½•ç»“æœï¼Œè·³è¿‡å¤„ç†');
        }
        break;
        
      case 'conversation.item.input_audio_transcription.failed':
        console.error('[CanvasVoiceController] è¯­éŸ³è½¬å½•å¤±è´¥:', event.error);
        onMessage?.('assistant', 'âŒ è¯­éŸ³è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•', 'system');
        break;
        
      case 'conversation.item.truncated':
        console.log('[CanvasVoiceController] å¯¹è¯é¡¹å·²æˆªæ–­:', event.item_id);
        break;
        
      case 'conversation.item.deleted':
        console.log('[CanvasVoiceController] å¯¹è¯é¡¹å·²åˆ é™¤:', event.item_id);
        break;
        
      // Input audio buffer events
      case 'input_audio_buffer.committed':
        console.log('[CanvasVoiceController] éŸ³é¢‘ç¼“å†²åŒºå·²æäº¤:', event.item_id);
        break;
        
      case 'input_audio_buffer.cleared':
        console.log('[CanvasVoiceController] éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º');
        break;
        
      case 'input_audio_buffer.speech_started':
        console.log('[CanvasVoiceController] æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹:', event.audio_start_ms);
        onMessage?.('user', 'ğŸ¤ æ­£åœ¨è¯´è¯...', 'voice');
        break;
        
      case 'input_audio_buffer.speech_stopped':
        console.log('[CanvasVoiceController] è¯­éŸ³ç»“æŸ:', event.audio_start_ms);
        break;
        
      // Response events
      case 'response.created':
        console.log('[CanvasVoiceController] AIå¼€å§‹å“åº”:', event.response?.id);
        onMessage?.('assistant', 'ğŸ¤” æ­£åœ¨æ€è€ƒ...', 'voice');
        break;
        
      case 'response.done':
        console.log('[CanvasVoiceController] AIå“åº”å®Œæˆ:', event.response?.status);
        break;
        
      // Output item events
      case 'response.output_item.added':
        console.log('[CanvasVoiceController] è¾“å‡ºé¡¹å·²æ·»åŠ :', event.item?.type);
        break;
        
      case 'response.output_item.done':
        console.log('[CanvasVoiceController] è¾“å‡ºé¡¹å®Œæˆ:', event.item?.status);
        break;
        
      // Content part events
      case 'response.content_part.added':
        console.log('[CanvasVoiceController] å†…å®¹éƒ¨åˆ†å·²æ·»åŠ :', event.part?.type);
        break;
        
      case 'response.content_part.done':
        if (event.part?.type === 'text' && event.part.text) {
          handleAssistantResponse(event.part.text);
        }
        break;
        
      // Text streaming events
      case 'response.text.delta':
        if (event.delta) {
          console.log('[CanvasVoiceController] æ–‡æœ¬å¢é‡:', event.delta);
          // å¯ä»¥å®ç°å®æ—¶æ–‡æœ¬æµæ˜¾ç¤º
        }
        break;
        
      case 'response.text.done':
        if (event.delta) {
          handleAssistantResponse(event.delta);
        }
        break;
        
      // Audio streaming events
      case 'response.audio.delta':
        if (event.delta) {
          console.log('[CanvasVoiceController] éŸ³é¢‘å¢é‡æ¥æ”¶');
          playAudioDelta(event.delta);
        }
        break;
        
      case 'response.audio.done':
        console.log('[CanvasVoiceController] éŸ³é¢‘æ’­æ”¾å®Œæˆ');
        break;
        
      // Audio transcript events
      case 'response.audio_transcript.delta':
        if (event.delta) {
          console.log('[CanvasVoiceController] éŸ³é¢‘è½¬å½•å¢é‡:', event.delta);
        }
        break;
        
      case 'response.audio_transcript.done':
        if (event.transcript) {
          console.log('[CanvasVoiceController] éŸ³é¢‘è½¬å½•å®Œæˆ:', event.transcript);
        }
        break;
        
      // Function call events
      case 'response.function_call_arguments.delta':
        if (event.delta) {
          console.log('[CanvasVoiceController] å‡½æ•°è°ƒç”¨å‚æ•°å¢é‡:', event.delta);
        }
        break;
        
      case 'response.function_call_arguments.done':
        if (event.arguments) {
          console.log('[CanvasVoiceController] å‡½æ•°è°ƒç”¨å‚æ•°å®Œæˆ:', event.arguments);
        }
        break;
        
      // Rate limits
      case 'rate_limits.updated':
        console.log('[CanvasVoiceController] é€Ÿç‡é™åˆ¶å·²æ›´æ–°:', event.rate_limits);
        break;
        
      // Error handling
      case 'error':
        console.error('[CanvasVoiceController] Realtime APIé”™è¯¯:', event.error);
        const errorMsg = event.error?.message || 'Unknown error';
        onMessage?.('assistant', `âŒ å‘ç”Ÿé”™è¯¯ï¼š${errorMsg}`, 'system');
        break;
        
      default:
        console.log('[CanvasVoiceController] æœªå¤„ç†çš„äº‹ä»¶ç±»å‹:', event.type);
    }
  };

  // åˆå§‹åŒ–æµè§ˆå™¨è¯­éŸ³è¯†åˆ«ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
  const initializeBrowserSpeech = () => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      
      const recognition = recognitionRef.current;
      recognition.continuous = true; // å¯ç”¨è¿ç»­ç›‘å¬
      recognition.interimResults = false; // ç¦ç”¨ä¸­é—´ç»“æœï¼Œé¿å…å¤„ç†ä¸å®Œæ•´çš„è¯­éŸ³
      recognition.lang = lang === 'zh' ? 'zh-CN' : 'en-US';

      recognition.onstart = () => {
        setIsListening(true);
        setError('');
        setErrorCount(0); // é‡ç½®é”™è¯¯è®¡æ•°
        console.log('[CanvasVoiceController] æµè§ˆå™¨è¯­éŸ³è¯†åˆ«å¯åŠ¨');
      };

      recognition.onresult = (event: SpeechRecognitionEvent) => {
        // åªå¤„ç†æœ€ç»ˆç»“æœï¼Œé¿å…å¤„ç†ç©ºçš„æˆ–ä¸å®Œæ•´çš„transcript
        const lastResult = event.results[event.results.length - 1];
        if (lastResult && lastResult.isFinal) {
          const transcript = lastResult[0].transcript.trim();
          
          // æ£€æŸ¥transcriptæ˜¯å¦æœ‰æ•ˆ
          if (transcript && transcript.length > 0) {
            console.log('[CanvasVoiceController] è¯­éŸ³è¯†åˆ«ç»“æœ:', transcript);
            
            // é˜²æŠ–å¤„ç†ï¼Œé¿å…é‡å¤å¤„ç†ç›¸åŒçš„æŒ‡ä»¤
            setTimeout(() => {
              handleVoiceCommand(transcript);
            }, 100);
          } else {
            console.log('[CanvasVoiceController] æ”¶åˆ°ç©ºçš„è¯­éŸ³è¯†åˆ«ç»“æœï¼Œè·³è¿‡å¤„ç†');
          }
        }
      };

      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        console.error('[CanvasVoiceController] è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        
        // æ›´æ–°é”™è¯¯è®¡æ•°å’Œæ—¶é—´
        const now = Date.now();
        if (now - lastErrorTime < 5000) { // 5ç§’å†…
          setErrorCount(prev => prev + 1);
        } else {
          setErrorCount(1); // é‡ç½®ä¸º1
        }
        setLastErrorTime(now);
        
        if (event.error === 'not-allowed') {
          setError(currentLang.micPermission);
          onMessage?.('assistant', `âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
1. ç‚¹å‡»åœ°å€æ å·¦ä¾§çš„ğŸ”’æˆ–ğŸ›¡ï¸å›¾æ ‡
2. å°†"éº¦å…‹é£"è®¾ç½®ä¸º"å…è®¸"
3. åˆ·æ–°é¡µé¢åé‡è¯•`, 'system');
          setIsListening(false);
          setIsProcessing(false);
        } else if (event.error === 'no-speech') {
          console.log('[CanvasVoiceController] æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œç»§ç»­ç›‘å¬...');
          // ä¸æ˜¾ç¤ºé”™è¯¯ï¼Œä¸è®¾ç½®isListeningä¸ºfalseï¼Œè®©onendå¤„ç†é‡å¯
        } else if (event.error === 'network') {
          console.log('[CanvasVoiceController] ç½‘ç»œé”™è¯¯ï¼Œå°è¯•é‡å¯...');
          // ç½‘ç»œé”™è¯¯æ—¶ä¸æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œä¸è®¾ç½®isListeningä¸ºfalseï¼Œè®©onendå¤„ç†é‡å¯
        } else if (event.error === 'aborted') {
          console.log('[CanvasVoiceController] è¯­éŸ³è¯†åˆ«è¢«ä¸­æ­¢ï¼Œåœæ­¢é‡å¯å¾ªç¯');
          // abortedé”™è¯¯é€šå¸¸æ˜¯ç”¨æˆ·ä¸»åŠ¨åœæ­¢æˆ–æµè§ˆå™¨ä¸­æ­¢ï¼Œä¸åº”è¯¥è‡ªåŠ¨é‡å¯
          setIsListening(false);
          setIsProcessing(false);
          return; // ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œåç»­ä»£ç 
        } else if (event.error === 'audio-capture') {
          console.log('[CanvasVoiceController] éŸ³é¢‘æ•è·é”™è¯¯ï¼Œåœæ­¢ç›‘å¬');
          setError('éŸ³é¢‘è®¾å¤‡è®¿é—®å¤±è´¥');
          setIsListening(false);
          setIsProcessing(false);
        } else {
          console.log('[CanvasVoiceController] å…¶ä»–è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
          // å¯¹äºå…¶ä»–é”™è¯¯ï¼Œä¹Ÿåœæ­¢è‡ªåŠ¨é‡å¯ï¼Œé¿å…æ— é™å¾ªç¯
          setIsListening(false);
          setIsProcessing(false);
        }
      };

      recognition.onend = () => {
        console.log('[CanvasVoiceController] è¯­éŸ³è¯†åˆ«ç»“æŸ');
        
        // æ£€æŸ¥é”™è¯¯é¢‘ç‡ï¼Œé˜²æ­¢æ— é™é‡å¯
        const now = Date.now();
        if (now - lastErrorTime < 5000) { // 5ç§’å†…
          setErrorCount(prev => prev + 1);
        } else {
          setErrorCount(0); // é‡ç½®é”™è¯¯è®¡æ•°
        }
        setLastErrorTime(now);
        
        // å¦‚æœé”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢è‡ªåŠ¨é‡å¯
        if (errorCount >= 3) {
          console.log('[CanvasVoiceController] é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢è‡ªåŠ¨é‡å¯');
          setIsListening(false);
          setIsProcessing(false);
          onMessage?.('assistant', 'è¯­éŸ³è¯†åˆ«å‡ºç°å¤šæ¬¡é”™è¯¯ï¼Œå·²åœæ­¢è‡ªåŠ¨é‡å¯ã€‚è¯·æ‰‹åŠ¨é‡æ–°æ¿€æ´»è¯­éŸ³æ§åˆ¶ã€‚', 'system');
          return;
        }
        
        // å¦‚æœä»ç„¶å¤„äºæ¿€æ´»çŠ¶æ€ä¸”æ²¡æœ‰å¤„ç†ä¸­ï¼Œè‡ªåŠ¨é‡å¯ç›‘å¬
        if (isActive && !isProcessing) {
          console.log('[CanvasVoiceController] è‡ªåŠ¨é‡å¯è¯­éŸ³ç›‘å¬...');
          setTimeout(() => {
            if (isActive && recognitionRef.current && !isProcessing) {
              try {
                recognitionRef.current.start();
              } catch (error) {
                console.error('[CanvasVoiceController] é‡å¯è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
                setIsListening(false);
                setIsProcessing(false);
              }
            }
          }, 500); // å‡å°‘å»¶è¿Ÿåˆ°500ms
        } else {
          setIsListening(false);
        }
      };
      
      // è‡ªåŠ¨å¼€å§‹ç›‘å¬
      startBrowserListening();
    } else {
      setError(currentLang.noSupport);
      onMessage?.('assistant', `âŒ ${currentLang.noSupport}

ğŸ’¡ å»ºè®®ä½¿ç”¨Chromeæˆ–Edgeæµè§ˆå™¨ä»¥è·å¾—æœ€ä½³è¯­éŸ³ä½“éªŒã€‚`, 'system');
    }
  };

  // ç§»é™¤äº†èŠå¤©ç›¸å…³çš„å‡½æ•°ï¼Œæ”¹ä¸ºä½¿ç”¨å›è°ƒé€šä¿¡

  const startBrowserListening = async () => {
    if (!recognitionRef.current) {
      setError(currentLang.noSupport);
      return;
    }

    try {
      // é¦–å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
      console.log('[CanvasVoiceController] è¯·æ±‚éº¦å…‹é£æƒé™...');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // æƒé™è·å–æˆåŠŸï¼Œå…³é—­æµï¼ˆæˆ‘ä»¬åªéœ€è¦æƒé™ï¼‰
      stream.getTracks().forEach(track => track.stop());
      console.log('[CanvasVoiceController] âœ… éº¦å…‹é£æƒé™å·²è·å¾—');

      setIsListening(true);
      setError('');
      recognitionRef.current.start();
      
      handleMessageUpdate('assistant', `ä½ å¥½ï¼æˆ‘æ˜¯${wakeWord}ï¼Œç°åœ¨å¯ä»¥ç›´æ¥è¯´è¯ï¼Œæˆ‘ä¼šå¬å–ä½ çš„æŒ‡ä»¤ã€‚`, 'system');
      
      console.log('[CanvasVoiceController] æµè§ˆå™¨è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
    } catch (error) {
      console.error('[CanvasVoiceController] å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      if (error instanceof Error && error.name === 'NotAllowedError') {
        setError('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®');
      } else if (error instanceof Error && error.name === 'NotFoundError') {
        setError('æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡');
      } else {
        setError('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }
      setIsListening(false);
    }
  };

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
      console.log('[CanvasVoiceController] è¯­éŸ³è¯†åˆ«å·²åœæ­¢');
    }
    
    // åœæ­¢éŸ³é¢‘å½•åˆ¶
    stopAudioRecording();
    
    // åœæ­¢æ‰€æœ‰è¯­éŸ³åˆæˆæ’­æ”¾
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
      console.log('[CanvasVoiceController] è¯­éŸ³åˆæˆå·²åœæ­¢');
    }
    
    // å…³é—­WebSocketè¿æ¥
    if (realtimeSession.ws && realtimeSession.isConnected) {
      realtimeSession.ws.close(1000, 'User stopped listening');
      setRealtimeSession({
        ws: null,
        sessionId: '',
        isConnected: false
      });
    }
  };

  // è¯­éŸ³è½¬å½•å®Œæˆæ—¶ï¼Œé€šè¿‡å›è°ƒé€šçŸ¥CaocaoAIChat
  const handleTranscriptionComplete = (transcript: string) => {
    console.log('[CanvasVoiceController] è¯­éŸ³è½¬å½•å®Œæˆ:', transcript);
    
    // æ£€æŸ¥è½¬å½•ç»“æœæ˜¯å¦æœ‰æ•ˆ
    if (!transcript || transcript.trim().length === 0) {
      console.log('[CanvasVoiceController] è½¬å½•ç»“æœä¸ºç©ºï¼Œè·³è¿‡å¤„ç†');
      return;
    }
    
    const trimmedTranscript = transcript.trim();
    handleMessageUpdate('user', trimmedTranscript, 'voice');
    
    // å¤„ç†è¯­éŸ³æŒ‡ä»¤ï¼Œæ·»åŠ é˜²æŠ–
    setTimeout(() => {
      handleVoiceCommand(trimmedTranscript);
    }, 100);
  };

  // AIå“åº”å®Œæˆæ—¶ï¼Œé€šè¿‡å›è°ƒé€šçŸ¥CaocaoAIChat
  const handleAssistantResponse = (content: string) => {
    console.log('[CanvasVoiceController] AIå“åº”å®Œæˆ:', content);
    handleMessageUpdate('assistant', content, 'voice');
    parseAndExecuteCommand(content);
    
    // æ’­æ”¾è¯­éŸ³å›å¤ï¼ˆå¦‚æœä¸æ˜¯å®æ—¶è¯­éŸ³æ¨¡å¼ï¼Œä½¿ç”¨TTSï¼‰
    if (!useRealtimeAPI || !realtimeSession.isConnected) {
      playTextToSpeech(content);
    }
  };

  // è§£æAIå“åº”ä¸­çš„æŒ‡ä»¤å¹¶æ‰§è¡Œ
  const parseAndExecuteCommand = (aiResponse: string) => {
    console.log('[CanvasVoiceController] è§£æAIå“åº”:', aiResponse);
    
    // æ£€æµ‹ç”ŸæˆæŒ‡ä»¤çš„å…³é”®è¯
    const lowerResponse = aiResponse.toLowerCase();
    
    let command: VoiceCommand | null = null;
    
    if (lowerResponse.includes('ç”Ÿæˆå›¾ç‰‡') || lowerResponse.includes('ç”»') || lowerResponse.includes('å›¾åƒ')) {
      // æå–å›¾ç‰‡æè¿°
      const imageMatch = aiResponse.match(/(?:ç”Ÿæˆ|ç”»|åˆ¶ä½œ).*?(?:å›¾ç‰‡|å›¾åƒ|ç”»é¢).*?[:ï¼š]?\s*(.+?)(?:[ã€‚ï¼ï¼Ÿ\n]|$)/);
      const content = imageMatch ? imageMatch[1].trim() : aiResponse;
      
      command = {
        command: 'generate_image',
        text: aiResponse,
        content: content,
        params: { aspectRatio: '1:1' }
      };
    } else if (lowerResponse.includes('ç”Ÿæˆè§†é¢‘') || lowerResponse.includes('åˆ¶ä½œè§†é¢‘') || lowerResponse.includes('è§†é¢‘')) {
      // æå–è§†é¢‘æè¿°
      const videoMatch = aiResponse.match(/(?:ç”Ÿæˆ|åˆ¶ä½œ).*?è§†é¢‘.*?[:ï¼š]?\s*(.+?)(?:[ã€‚ï¼ï¼Ÿ\n]|$)/);
      const content = videoMatch ? videoMatch[1].trim() : aiResponse;
      
      command = {
        command: 'generate_video',
        text: aiResponse,
        content: content,
        params: { duration: 10, aspectRatio: '16:9' }
      };
    } else if (lowerResponse.includes('å†™') || lowerResponse.includes('æ–‡æœ¬') || lowerResponse.includes('æ–‡å­—')) {
      // æå–æ–‡æœ¬å†…å®¹
      const textMatch = aiResponse.match(/(?:å†™|ç”Ÿæˆ|åˆ›å»º).*?(?:æ–‡æœ¬|æ–‡å­—|å†…å®¹).*?[:ï¼š]?\s*(.+?)(?:[ã€‚ï¼ï¼Ÿ\n]|$)/);
      const content = textMatch ? textMatch[1].trim() : aiResponse;
      
      command = {
        command: 'generate_text',
        text: aiResponse,
        content: content
      };
    }
    
    // æ‰§è¡ŒæŒ‡ä»¤
    if (command) {
      console.log('[CanvasVoiceController] æ‰§è¡Œè¯­éŸ³æŒ‡ä»¤:', command);
      onCommand(command);
    }
  };

  // å¼€å§‹éŸ³é¢‘å½•åˆ¶
  const startAudioRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      // åˆ›å»ºAudioContextç”¨äºéŸ³é¢‘å¤„ç†
      const audioCtx = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });
      setAudioContext(audioCtx);
      
      // åˆ›å»ºMediaRecorderå½•åˆ¶éŸ³é¢‘
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          
          // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºPCM16æ ¼å¼å¹¶å‘é€åˆ°WebSocket
          convertAndSendAudio(event.data);
        }
      };
      
      recorder.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®
      setMediaRecorder(recorder);
      
      console.log('[CanvasVoiceController] âœ… éŸ³é¢‘å½•åˆ¶å·²å¼€å§‹');
      
    } catch (error) {
      console.error('[CanvasVoiceController] éŸ³é¢‘å½•åˆ¶å¯åŠ¨å¤±è´¥:', error);
      onMessage?.('assistant', 'âŒ æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®', 'system');
    }
  };

  // è½¬æ¢éŸ³é¢‘æ ¼å¼å¹¶å‘é€åˆ°WebSocket
  const convertAndSendAudio = async (audioBlob: Blob) => {
    if (!realtimeSession.ws || !realtimeSession.isConnected) return;
    
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioContext = new AudioContext({ sampleRate: 16000 });
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // è½¬æ¢ä¸ºPCM16æ ¼å¼
      const pcm16Data = convertToPCM16(audioBuffer);
      const base64Audio = btoa(String.fromCharCode(...pcm16Data));
      
      // å‘é€éŸ³é¢‘æ•°æ®åˆ°Realtime API
      const audioEvent = {
        event_id: `audio_${Date.now()}`,
        type: 'input_audio_buffer.append',
        audio: base64Audio
      };
      
      realtimeSession.ws.send(JSON.stringify(audioEvent));
      
    } catch (error) {
      console.error('[CanvasVoiceController] éŸ³é¢‘è½¬æ¢å¤±è´¥:', error);
    }
  };

  // è½¬æ¢AudioBufferåˆ°PCM16æ ¼å¼
  const convertToPCM16 = (audioBuffer: AudioBuffer): Uint8Array => {
    const samples = audioBuffer.getChannelData(0);
    const pcm16 = new Int16Array(samples.length);
    
    for (let i = 0; i < samples.length; i++) {
      const sample = Math.max(-1, Math.min(1, samples[i]));
      pcm16[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
    }
    
    return new Uint8Array(pcm16.buffer);
  };

  // æ’­æ”¾AIè¯­éŸ³å›å¤
  const playAudioDelta = async (base64Audio: string) => {
    if (!audioContext) return;
    
    try {
      // è§£ç base64éŸ³é¢‘æ•°æ®
      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      
      // è½¬æ¢PCM16æ•°æ®ä¸ºAudioBuffer
      const audioBuffer = audioContext.createBuffer(1, bytes.length / 2, 16000);
      const channelData = audioBuffer.getChannelData(0);
      
      const dataView = new DataView(bytes.buffer);
      for (let i = 0; i < channelData.length; i++) {
        channelData[i] = dataView.getInt16(i * 2, true) / 0x8000;
      }
      
      // æ’­æ”¾éŸ³é¢‘
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      source.start();
      
      console.log('[CanvasVoiceController] âœ… éŸ³é¢‘æ’­æ”¾æˆåŠŸ');
      
    } catch (error) {
      console.error('[CanvasVoiceController] éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
    }
  };

  // æ’­æ”¾æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
  const playTextToSpeech = (text: string) => {
    if ('speechSynthesis' in window) {
      // åœæ­¢å½“å‰æ’­æ”¾çš„è¯­éŸ³
      window.speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = lang === 'zh' ? 'zh-CN' : 'en-US';
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      utterance.volume = 0.8;
      
      utterance.onstart = () => {
        console.log('[CanvasVoiceController] å¼€å§‹æ’­æ”¾TTSè¯­éŸ³:', text.substring(0, 50));
      };
      
      utterance.onend = () => {
        console.log('[CanvasVoiceController] TTSè¯­éŸ³æ’­æ”¾å®Œæˆ');
      };
      
      utterance.onerror = (event) => {
        console.error('[CanvasVoiceController] TTSæ’­æ”¾å¤±è´¥:', event.error);
      };
      
      // ç¡®ä¿è¯­éŸ³åˆæˆå™¨å¤„äºæ­£ç¡®çŠ¶æ€
      if (window.speechSynthesis.paused) {
        window.speechSynthesis.resume();
      }
      
      window.speechSynthesis.speak(utterance);
      console.log('[CanvasVoiceController] TTSè¯­éŸ³å·²åŠ å…¥æ’­æ”¾é˜Ÿåˆ—');
    } else {
      console.warn('[CanvasVoiceController] æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ');
    }
  };

  // åœæ­¢éŸ³é¢‘å½•åˆ¶
  const stopAudioRecording = () => {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
      setMediaRecorder(null);
    }
    
    if (audioContext && audioContext.state !== 'closed') {
      audioContext.close();
      setAudioContext(null);
    }
    
    audioChunksRef.current = [];
    console.log('[CanvasVoiceController] éŸ³é¢‘å½•åˆ¶å·²åœæ­¢');
  };

  const handleVoiceCommand = async (transcript: string) => {
    try {
      setIsProcessing(true);
      
      // æ£€æŸ¥ç©ºå­—ç¬¦ä¸²æˆ–æ— æ•ˆè¾“å…¥ï¼Œé¿å…æ— é™å¾ªç¯
      if (!transcript || transcript.trim().length === 0) {
        console.log('[CanvasVoiceController] æ”¶åˆ°ç©ºå­—ç¬¦ä¸²ï¼Œè·³è¿‡å¤„ç†');
        return; // ä¸è®¾ç½®setIsProcessing(false)ï¼Œè®©finallyå¤„ç†
      }
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤çš„é”™è¯¯æ¶ˆæ¯ï¼Œé¿å…æ— é™å¾ªç¯
      const trimmedTranscript = transcript.trim().toLowerCase();
      if (trimmedTranscript.includes('æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æŒ‡ä»¤') || 
          trimmedTranscript.includes('sorry, i didn\'t understand')) {
        console.log('[CanvasVoiceController] æ£€æµ‹åˆ°é‡å¤é”™è¯¯æ¶ˆæ¯ï¼Œè·³è¿‡å¤„ç†');
        return; // ä¸è®¾ç½®setIsProcessing(false)ï¼Œè®©finallyå¤„ç†
      }
      
      // æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
      handleMessageUpdate('user', transcript, 'voice');
      handleMessageUpdate('assistant', 'æ­£åœ¨å¤„ç†æ‚¨çš„æŒ‡ä»¤...', 'voice');
      
      console.log('[CanvasVoiceController] å¤„ç†è¯­éŸ³æŒ‡ä»¤:', transcript);
      
      // ğŸ”¥ ä¼˜å…ˆæ£€æŸ¥æ¨¡å—æ“ä½œæŒ‡ä»¤ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
      const moduleCommand = voiceCanvasReporter.parseModuleCommand(transcript, lang as 'zh' | 'en');
      
      if (moduleCommand) {
        console.log('[CanvasVoiceController] è¯†åˆ«åˆ°æ¨¡å—æ“ä½œæŒ‡ä»¤:', moduleCommand);
        
        // æ‰§è¡Œæ¨¡å—æ“ä½œ
        const result = await handleModuleCommand(moduleCommand);
        
        if (result.success) {
          handleMessageUpdate('assistant', result.message, 'voice');
          playTextToSpeech(result.message);
        } else {
          handleMessageUpdate('assistant', result.message, 'voice');
          playTextToSpeech(result.message);
        }
        
        return;
      }
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯ç”»å¸ƒçŠ¶æ€æŸ¥è¯¢
      const lowerTranscript = transcript.toLowerCase();
      if (lowerTranscript.includes('ç”»å¸ƒçŠ¶æ€') || lowerTranscript.includes('æ’­æŠ¥') || 
          lowerTranscript.includes('canvas status') || lowerTranscript.includes('report')) {
        
        const report = voiceCanvasReporter.generateDetailedReport(blocks, lang as 'zh' | 'en');
        handleMessageUpdate('assistant', report, 'voice');
        
        // æ’­æ”¾ç®€åŒ–ç‰ˆæœ¬çš„è¯­éŸ³
        const summary = voiceCanvasReporter.generateCanvasReport(blocks, lang as 'zh' | 'en').summary;
        const voiceReport = lang === 'zh' 
          ? `ç”»å¸ƒçŠ¶æ€ï¼š${summary}ã€‚è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹èŠå¤©ç•Œé¢ã€‚`
          : `Canvas status: ${summary}. Check chat for details.`;
        
        playTextToSpeech(voiceReport);
        return;
      }
      
      // å¦‚æœä¸æ˜¯æ¨¡å—æ“ä½œï¼ŒæŒ‰åŸæ¥çš„æ–¹å¼å¤„ç†å†…å®¹ç”ŸæˆæŒ‡ä»¤
      const command = await parseVoiceCommand(transcript);
      
      console.log('[CanvasVoiceController] è§£æçš„è¯­éŸ³æŒ‡ä»¤:', command);
      
      // ç›´æ¥æ‰§è¡ŒæŒ‡ä»¤ï¼Œä¸ç­‰å¾…AIå›å¤
      if (command.command !== 'unknown') {
        // ç«‹å³æ‰§è¡ŒæŒ‡ä»¤
        onCommand(command);
        
        // ç”Ÿæˆå›å¤æ–‡æœ¬ï¼Œä¸é¢„æµ‹ç¼–å·ï¼Œç­‰åˆ›å»ºå®Œæˆåå†æ’­æŠ¥
        let responseText = '';
        
        switch (command.command) {
          case 'generate_text':
            responseText = lang === 'zh' 
              ? `å¥½çš„ï¼Œæˆ‘æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆæ–‡æœ¬æ¨¡å—ï¼š"${command.content}"`
              : `Alright, I'm generating text module for you: "${command.content}"`;
            break;
          case 'generate_image':
            responseText = lang === 'zh'
              ? `å¥½çš„ï¼Œæˆ‘æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆå›¾ç‰‡æ¨¡å—ï¼š"${command.content}"`
              : `Alright, I'm generating image module for you: "${command.content}"`;
            break;
          case 'generate_video':
            responseText = lang === 'zh'
              ? `å¥½çš„ï¼Œæˆ‘æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆè§†é¢‘æ¨¡å—ï¼š"${command.content}"`
              : `Alright, I'm generating video module for you: "${command.content}"`;
            break;
          case 'add_to_canvas':
            responseText = lang === 'zh'
              ? `å¥½çš„ï¼Œæˆ‘æ­£åœ¨å°†å†…å®¹æ·»åŠ åˆ°ç”»å¸ƒä¸Š`
              : `Alright, I'm adding the content to the canvas`;
            break;
          default:
            responseText = lang === 'zh'
              ? `æˆ‘ç†è§£äº†æ‚¨çš„éœ€æ±‚ï¼š"${command.content}"ï¼Œæ­£åœ¨å¤„ç†ä¸­...`
              : `I understand your request: "${command.content}", processing...`;
        }
        
        // æ˜¾ç¤ºAIå›å¤
        handleMessageUpdate('assistant', responseText, 'voice');
        
        // æ’­æ”¾è¯­éŸ³å›å¤
        playTextToSpeech(responseText);
        
      } else {
        // æœªè¯†åˆ«çš„æŒ‡ä»¤ - é™åˆ¶é”™è¯¯æ¶ˆæ¯é¢‘ç‡ï¼Œé¿å…æ— é™å¾ªç¯
        console.log('[CanvasVoiceController] æœªè¯†åˆ«çš„æŒ‡ä»¤ï¼Œä½†ä¸æ’­æ”¾é”™è¯¯æ¶ˆæ¯ä»¥é¿å…å¾ªç¯');
        
        const errorText = lang === 'zh'
          ? `è¯·è¯´å‡ºæ˜ç¡®çš„æŒ‡ä»¤ï¼Œæ¯”å¦‚"ç”Ÿæˆå›¾ç‰‡"ã€"å†™æ–‡å­—"æˆ–"åˆ¶ä½œè§†é¢‘"`
          : `Please speak clear commands like "generate image", "write text", or "create video"`;
        
        handleMessageUpdate('assistant', errorText, 'voice');
        // ä¸æ’­æ”¾TTSï¼Œé¿å…æ— é™å¾ªç¯
        // playTextToSpeech(errorText);
      }
      
    } catch (error) {
      console.error('è¯­éŸ³æŒ‡ä»¤å¤„ç†å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯APIå¯†é’¥é—®é¢˜
      if (errorMessage.includes('PLACEHOLDER_API_KEY') || 
          errorMessage.includes('APIå¯†é’¥æœªé…ç½®') ||
          errorMessage.includes('network') ||
          errorMessage.includes('401') ||
          errorMessage.includes('unauthorized')) {
        onMessage?.('assistant', `âŒ APIå¯†é’¥æœªé…ç½®ï¼

ğŸ”‘ å¿«é€Ÿé…ç½®æ–¹æ³•ï¼š
1. ç‚¹å‡»å³ä¾§è¾¹æ çš„"è®¾ç½®"âš™ï¸æŒ‰é’®
2. åœ¨"APIæä¾›å•†é…ç½®"ä¸­è¾“å…¥ä½ çš„Gemini APIå¯†é’¥
3. ç‚¹å‡»"ä¿å­˜é…ç½®"

ğŸ“ è·å–APIå¯†é’¥ï¼š
â€¢ è®¿é—®ï¼šhttps://aistudio.google.com/app/apikey
â€¢ ç™»å½•Googleè´¦å·å¹¶åˆ›å»ºAPIå¯†é’¥
â€¢ å¤åˆ¶å¯†é’¥åˆ°è®¾ç½®ä¸­

ğŸ’¡ é…ç½®å®Œæˆåï¼Œè¯­éŸ³æ§åˆ¶å°†èƒ½æ­£å¸¸å·¥ä½œï¼`, 'system');
      } else {
        onMessage?.('assistant', `æŠ±æ­‰ï¼Œå¤„ç†æŒ‡ä»¤æ—¶å‡ºç°é”™è¯¯ï¼š${errorMessage}

ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
â€¢ ç¡®è®¤APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
â€¢ ç¨åé‡è¯•è¯­éŸ³æŒ‡ä»¤

å¦‚éœ€å¸®åŠ©ï¼Œè¯·ç‚¹å‡»å³ä¾§è¾¹æ çš„"è®¾ç½®"æŒ‰é’®æ£€æŸ¥é…ç½®ã€‚`, 'system');
      }
    } finally {
      setIsProcessing(false);
    }
  };

  /**
   * å¤„ç†æ¨¡å—æ“ä½œæŒ‡ä»¤
   */
  const handleModuleCommand = async (command: VoiceModuleCommand): Promise<{success: boolean, message: string}> => {
    console.log('[CanvasVoiceController] æ‰§è¡Œæ¨¡å—æ“ä½œ:', command);
    
    // æ£€æŸ¥ç›®æ ‡æ¨¡å—æ˜¯å¦å­˜åœ¨
    if (command.targetModule) {
      const targetBlock = blocks.find(b => b.number === command.targetModule);
      if (!targetBlock && command.action !== 'generate') {
        const message = lang === 'zh' 
          ? `æ¨¡å—${command.targetModule}ä¸å­˜åœ¨ã€‚å½“å‰ç”»å¸ƒæœ‰ï¼š${blocks.map(b => b.number).join('ã€') || 'æ— æ¨¡å—'}`
          : `Module ${command.targetModule} does not exist. Current canvas has: ${blocks.map(b => b.number).join(', ') || 'no modules'}`;
        return { success: false, message };
      }
    }
    
    // æ‰§è¡Œç›¸åº”çš„æ“ä½œ
    switch (command.action) {
      case 'select':
        onModuleAction?.('select', command.targetModule);
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²é€‰æ‹©æ¨¡å—${command.targetModule}`
            : `Selected module ${command.targetModule}`
        };
        
      case 'delete':
        onModuleAction?.('delete', command.targetModule);
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²åˆ é™¤æ¨¡å—${command.targetModule}`
            : `Deleted module ${command.targetModule}`
        };
        
      case 'generate':
        onModuleAction?.('generate', command.targetModule, { content: command.content });
        return {
          success: true,
          message: lang === 'zh' 
            ? `æ­£åœ¨ä¸ºæ¨¡å—${command.targetModule}ç”Ÿæˆå†…å®¹ï¼š"${command.content}"`
            : `Generating content for module ${command.targetModule}: "${command.content}"`
        };

      case 'edit':
        onModuleAction?.('edit', command.targetModule, { content: command.content });
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²ä¸ºæ¨¡å—${command.targetModule}è¾“å…¥å†…å®¹ï¼š"${command.content}"`
            : `Input content for module ${command.targetModule}: "${command.content}"`
        };

      case 'regenerate':
        onModuleAction?.('regenerate', command.targetModule);
        return {
          success: true,
          message: lang === 'zh' 
            ? `æ­£åœ¨é‡æ–°ç”Ÿæˆæ¨¡å—${command.targetModule}çš„å†…å®¹`
            : `Regenerating content for module ${command.targetModule}`
        };

      case 'modify_prompt':
        onModuleAction?.('modify_prompt', command.targetModule, { 
          promptModification: command.promptModification 
        });
        return {
          success: true,
          message: lang === 'zh' 
            ? `æ­£åœ¨ä¸ºæ¨¡å—${command.targetModule}çš„æç¤ºè¯æ·»åŠ ï¼š"${command.promptModification}"`
            : `Adding to module ${command.targetModule} prompt: "${command.promptModification}"`
        };
        
      case 'move':
        onModuleAction?.('move', command.targetModule, { direction: command.direction });
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²å°†æ¨¡å—${command.targetModule}å‘${getDirectionText(command.direction!, lang)}ç§»åŠ¨`
            : `Moved module ${command.targetModule} ${command.direction}`
        };
        
      case 'connect':
        onModuleAction?.('connect', command.targetModule, { connectTo: command.connectTo });
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²å°†æ¨¡å—${command.targetModule}è¿æ¥åˆ°${command.connectTo}`
            : `Connected module ${command.targetModule} to ${command.connectTo}`
        };
        
      case 'copy':
        onModuleAction?.('copy', command.targetModule);
        return {
          success: true,
          message: lang === 'zh' 
            ? `å·²å¤åˆ¶æ¨¡å—${command.targetModule}`
            : `Copied module ${command.targetModule}`
        };
        
      default:
        return {
          success: false,
          message: lang === 'zh' 
            ? `ä¸æ”¯æŒçš„æ“ä½œï¼š${command.action}`
            : `Unsupported action: ${command.action}`
        };
    }
  };

  /**
   * è·å–ä¸‹ä¸€ä¸ªæ¨¡å—ç¼–å·
   */
  const getNextModuleNumber = (type: string): string => {
    const prefix = type === 'generate_text' ? 'A' : type === 'generate_image' ? 'B' : 'V';
    const blockType = type === 'generate_text' ? 'text' : type === 'generate_image' ? 'image' : 'video';
    
    // ç®€åŒ–ç¼–å·ç”Ÿæˆï¼šåªæ‰¾æœ€å¤§ç¼–å·+1ï¼Œä¸å¡«è¡¥ç©ºç¼º
    const sameTypeBlocks = blocks.filter(b => b.type === blockType);
    
    // æ‰¾åˆ°å½“å‰æœ€å¤§çš„ç¼–å·
    let maxNumber = 0;
    sameTypeBlocks.forEach(b => {
      const match = b.number.match(/\d+/);
      if (match) {
        const num = parseInt(match[0]);
        if (num > maxNumber) {
          maxNumber = num;
        }
      }
    });
    
    // ä¸‹ä¸€ä¸ªç¼–å·å°±æ˜¯æœ€å¤§ç¼–å·+1
    const nextNumber = maxNumber + 1;
    return `${prefix}${String(nextNumber).padStart(2, '0')}`;
  };

  /**
   * è·å–æ–¹å‘æ–‡æœ¬
   */
  const getDirectionText = (direction: string, lang: 'zh' | 'en'): string => {
    if (lang === 'zh') {
      switch (direction) {
        case 'up': return 'ä¸Š';
        case 'down': return 'ä¸‹';
        case 'left': return 'å·¦';
        case 'right': return 'å³';
        default: return direction;
      }
    }
    return direction;
  };

  const parseVoiceCommand = async (transcript: string): Promise<VoiceCommand> => {
    const text = transcript.toLowerCase();
    
    console.log('[CanvasVoiceController] è§£æè¯­éŸ³æŒ‡ä»¤:', { transcript, text });
    
    if (lang === 'zh') {
      // ä¸­æ–‡æŒ‡ä»¤è¯†åˆ« - æ›´å®½æ¾çš„åŒ¹é…
      if (text.includes('å†™') || text.includes('æ–‡å­—') || text.includes('æ–‡æœ¬') || text.includes('æ–‡ç« ') || text.includes('å†…å®¹')) {
        const content = transcript.replace(/æ›¹æ“|å¸®æˆ‘|è¯·|å†™|æ–‡å­—|æ–‡æœ¬|æ–‡ç« |å†…å®¹|ç”Ÿæˆ|åˆ¶ä½œ/g, '').trim();
        return { 
          command: 'generate_text', 
          text: transcript,
          content: content || 'è¯·å†™ä¸€æ®µæ–‡å­—'
        };
      } else if (text.includes('è§†é¢‘') || text.includes('å½•åƒ') || text.includes('åŠ¨ç”»') || text.includes('å½±ç‰‡')) {
        const duration = text.includes('çŸ­') ? 15 : text.includes('é•¿') ? 60 : 30;
        const content = transcript.replace(/æ›¹æ“|å¸®æˆ‘|è¯·|è§†é¢‘|å½•åƒ|åŠ¨ç”»|å½±ç‰‡|ç”Ÿæˆ|åˆ¶ä½œ/g, '').trim();
        return { 
          command: 'generate_video', 
          text: transcript,
          content: content || 'åˆ¶ä½œä¸€ä¸ªè§†é¢‘',
          params: { duration }
        };
      } else if (text.includes('å›¾ç‰‡') || text.includes('ç”»') || text.includes('å›¾åƒ') || text.includes('å›¾') || text.includes('ç…§ç‰‡')) {
        const aspectRatio = text.includes('9:16') || text.includes('ç«–å±') ? '9:16' : 
                           text.includes('16:9') || text.includes('æ¨ªå±') ? '16:9' : '1:1';
        const content = transcript.replace(/æ›¹æ“|å¸®æˆ‘|è¯·|å›¾ç‰‡|ç”»|å›¾åƒ|å›¾|ç…§ç‰‡|ç”Ÿæˆ|åˆ¶ä½œ/g, '').trim();
        return { 
          command: 'generate_image', 
          text: transcript,
          content: content || 'ç”Ÿæˆä¸€å¼ å›¾ç‰‡',
          params: { aspectRatio }
        };
      } else if (text.includes('æ·»åŠ ') || text.includes('æ”¾åˆ°') || text.includes('ç”»å¸ƒ')) {
        const content = transcript.replace(/æ›¹æ“|å¸®æˆ‘|è¯·|æ·»åŠ |æ”¾åˆ°|ç”»å¸ƒ/g, '').trim();
        return { 
          command: 'add_to_canvas', 
          text: transcript,
          content: content
        };
      }
    } else {
      // English commands - æ›´å®½æ¾çš„åŒ¹é…
      if (text.includes('write') || text.includes('text') || text.includes('create text') || text.includes('article')) {
        const content = transcript.replace(/caocao|please|help me|write|text|create text|article|generate|make/gi, '').trim();
        return { 
          command: 'generate_text', 
          text: transcript,
          content: content || 'write some text'
        };
      } else if (text.includes('video') || text.includes('movie') || text.includes('animation') || text.includes('film')) {
        const duration = text.includes('short') ? 15 : text.includes('long') ? 60 : 30;
        const content = transcript.replace(/caocao|please|help me|video|movie|animation|film|create|generate|make/gi, '').trim();
        return { 
          command: 'generate_video', 
          text: transcript,
          content: content || 'create a video',
          params: { duration }
        };
      } else if (text.includes('image') || text.includes('picture') || text.includes('photo') || text.includes('draw')) {
        const aspectRatio = text.includes('portrait') || text.includes('vertical') ? '9:16' : 
                           text.includes('landscape') || text.includes('horizontal') ? '16:9' : '1:1';
        const content = transcript.replace(/caocao|please|help me|image|picture|photo|draw|create|generate|make/gi, '').trim();
        return { 
          command: 'generate_image', 
          text: transcript,
          content: content || 'generate an image',
          params: { aspectRatio }
        };
      } else if (text.includes('add') || text.includes('put') || text.includes('canvas')) {
        const content = transcript.replace(/caocao|please|help me|add|put|canvas/gi, '').trim();
        return { 
          command: 'add_to_canvas', 
          text: transcript,
          content: content
        };
      }
    }
    
    console.log('[CanvasVoiceController] æœªè¯†åˆ«çš„æŒ‡ä»¤:', transcript);
    return { 
      command: 'unknown', 
      text: transcript,
      content: transcript
    };
  };

  // ç§»é™¤äº†handleSendMessageå’ŒhandleKeyPresså‡½æ•°ï¼Œå› ä¸ºä¸å†éœ€è¦ç‹¬ç«‹çš„è¾“å…¥æ¡†

  // æ–°å¢ï¼šç®¡ç†æ˜¾ç¤ºçš„å¯¹è¯æ¶ˆæ¯
  const [displayMessages, setDisplayMessages] = useState<Array<{
    id: string;
    role: 'user' | 'assistant';
    content: string;
    timestamp: number;
  }>>([]);

  // æ·»åŠ æ¶ˆæ¯åˆ°æ˜¾ç¤ºåˆ—è¡¨ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘2è½®å¯¹è¯ï¼‰
  const addDisplayMessage = useCallback((role: 'user' | 'assistant', content: string) => {
    // è¿‡æ»¤æ‰ç³»ç»Ÿæ¶ˆæ¯å’ŒåŒ…å«ç‰¹æ®Šç¬¦å·çš„æ¶ˆæ¯
    if (content.includes('âŒ') || content.includes('âœ…') || content.includes('ğŸ”‘') || 
        content.includes('è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤') || content.includes('ğŸ”§') || content.includes('ğŸ’¡')) {
      return;
    }

    const newMessage = {
      id: `display_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      role,
      content,
      timestamp: Date.now()
    };

    setDisplayMessages(prev => {
      const updated = [...prev, newMessage];
      // ä¿ç•™æœ€è¿‘2è½®å¯¹è¯ï¼ˆ4æ¡æ¶ˆæ¯ï¼šç”¨æˆ·-åŠ©æ‰‹-ç”¨æˆ·-åŠ©æ‰‹ï¼‰
      return updated.slice(-4);
    });
  }, []);

  // å°†addDisplayMessageå‡½æ•°ä¼ é€’ç»™å¤–éƒ¨ç»„ä»¶
  useEffect(() => {
    if (onDisplayMessageUpdate) {
      onDisplayMessageUpdate(addDisplayMessage);
    }
  }, [onDisplayMessageUpdate, addDisplayMessage]);

  // é‡å†™æ¶ˆæ¯å¤„ç†ï¼ŒåŒæ—¶æ›´æ–°æ˜¾ç¤ºæ¶ˆæ¯
  const handleMessageUpdate = useCallback((role: 'user' | 'assistant', content: string, type?: 'voice' | 'system') => {
    // è°ƒç”¨åŸå§‹çš„onMessageå›è°ƒ
    onMessage?.(role, content, type);
    
    // æ›´æ–°æ˜¾ç¤ºæ¶ˆæ¯ï¼ˆè¿‡æ»¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
    if (type !== 'system') {
      addDisplayMessage(role, content);
    }
  }, [onMessage, addDisplayMessage]);

  return (
    <>
      {/* è¯­éŸ³å¯¹è¯æ˜¾ç¤º - å‚ç›´æ’ç‰ˆï¼Œæœºå™¨äººå’Œç”¨æˆ·å„å ä¸€è¡Œ */}
      {isActive && (
        <div className="fixed top-6 left-96 z-[350] pointer-events-none">
          <div className="flex flex-col gap-1 max-w-2xl">
            {/* çŠ¶æ€æŒ‡ç¤º - å›ºå®šåœ¨é¡¶éƒ¨ */}
            <div className="flex-shrink-0">
              <span className="text-sm font-bold text-slate-700 dark:text-slate-300 drop-shadow-lg">
                {isListening ? 'ğŸ¤ è¯­éŸ³ç›‘å¬ä¸­' : 'â¸ï¸ è¯­éŸ³å·²æš‚åœ'}
              </span>
            </div>

            {/* å¯¹è¯å†…å®¹ - å‚ç›´æ’åˆ—ï¼Œæœºå™¨äººå’Œç”¨æˆ·å„å ä¸€è¡Œ */}
            <div className="flex flex-col gap-1">
              {displayMessages.length === 0 ? (
                <div className="text-sm font-medium text-purple-600 dark:text-purple-400 drop-shadow-lg">
                  ğŸ’¡ è¯•è¯•è¯´ï¼š"æ›¹æ“ï¼Œç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡"
                </div>
              ) : (
                <>
                  {/* ç”¨æˆ·æ¶ˆæ¯è¡Œ */}
                  {(() => {
                    const userMessage = displayMessages.filter(m => m.role === 'user').slice(-1)[0];
                    return userMessage ? (
                      <div key={`user-${userMessage.id}`} className="flex items-center gap-2 animate-in slide-in-from-right duration-300">
                        <span className="text-sm font-bold text-green-600 dark:text-green-400 drop-shadow-lg">
                          ğŸ‘¤
                        </span>
                        <span className="text-lg font-bold text-green-700 dark:text-green-300 drop-shadow-lg">
                          {userMessage.content.length > 40 
                            ? userMessage.content.substring(0, 40) + '...' 
                            : userMessage.content
                          }
                        </span>
                      </div>
                    ) : null;
                  })()}

                  {/* æœºå™¨äººæ¶ˆæ¯è¡Œ */}
                  {(() => {
                    const assistantMessage = displayMessages.filter(m => m.role === 'assistant').slice(-1)[0];
                    return assistantMessage ? (
                      <div key={`assistant-${assistantMessage.id}`} className="flex items-center gap-2 animate-in slide-in-from-right duration-300">
                        <span className="text-sm font-bold text-purple-600 dark:text-purple-400 drop-shadow-lg">
                          ğŸ¤–
                        </span>
                        <span className="text-lg font-bold text-purple-700 dark:text-purple-300 drop-shadow-lg">
                          {assistantMessage.content.length > 40 
                            ? assistantMessage.content.substring(0, 40) + '...' 
                            : assistantMessage.content
                          }
                        </span>
                      </div>
                    ) : null;
                  })()}
                </>
              )}
            </div>
          </div>
        </div>
      )}

      {/* é”™è¯¯æç¤º */}
      {error && (
        <div 
          className="fixed z-50 bg-red-500 text-white px-4 py-2 rounded-lg shadow-lg text-sm font-medium"
          style={{ left: position.x, top: position.y + 200 }}
        >
          âŒ {error}
        </div>
      )}
    </>
  );
};

export default CanvasVoiceController;